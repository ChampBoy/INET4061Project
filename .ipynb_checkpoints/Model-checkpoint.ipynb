{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import applications\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import linear_model, metrics, svm, neighbors, gaussian_process, ensemble, neural_network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totPurchaseAmt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>livingArea</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>averageSchoolRating</th>\n",
       "      <th>zip</th>\n",
       "      <th>zestimate</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198000.0</td>\n",
       "      <td>45.237189</td>\n",
       "      <td>-93.409535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>55303</td>\n",
       "      <td>285985.0</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415000.0</td>\n",
       "      <td>45.278217</td>\n",
       "      <td>-93.407533</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3108.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55303</td>\n",
       "      <td>431995.0</td>\n",
       "      <td>0.2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329900.0</td>\n",
       "      <td>45.143781</td>\n",
       "      <td>-93.021604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>55038</td>\n",
       "      <td>318162.0</td>\n",
       "      <td>0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>262000.0</td>\n",
       "      <td>45.164166</td>\n",
       "      <td>-93.297836</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>55043</td>\n",
       "      <td>272169.0</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>280000.0</td>\n",
       "      <td>45.283700</td>\n",
       "      <td>-93.332023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>55304</td>\n",
       "      <td>290365.0</td>\n",
       "      <td>0.9428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totPurchaseAmt   latitude  longitude  bathrooms  bedrooms  livingArea  \\\n",
       "1        198000.0  45.237189 -93.409535        2.0       4.0      1716.0   \n",
       "3        415000.0  45.278217 -93.407533        2.0       3.0      3108.0   \n",
       "4        329900.0  45.143781 -93.021604        3.0       4.0      1814.0   \n",
       "5        262000.0  45.164166 -93.297836        2.0       3.0      2158.0   \n",
       "6        280000.0  45.283700 -93.332023        2.0       3.0      1993.0   \n",
       "\n",
       "   yearBuilt  averageSchoolRating    zip  zestimate  sentiment  \n",
       "1       1996             5.333333  55303   285985.0     0.4939  \n",
       "3       1985             6.333333  55303   431995.0     0.2617  \n",
       "4       2001             6.500000  55038   318162.0     0.2732  \n",
       "5       1985             4.666667  55043   272169.0     0.9136  \n",
       "6       1976             7.333333  55304   290365.0     0.9428  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open(\"datafiles/after-EDA.ft\", \"rb\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26789"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('zip')\n",
    "df = grouped.filter(lambda x: x['zip'].count() > 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Categorical Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totPurchaseAmt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>livingArea</th>\n",
       "      <th>yearBuilt</th>\n",
       "      <th>averageSchoolRating</th>\n",
       "      <th>zestimate</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>bathrooms_1.0</th>\n",
       "      <th>bathrooms_1.2</th>\n",
       "      <th>...</th>\n",
       "      <th>zip_55437</th>\n",
       "      <th>zip_55441</th>\n",
       "      <th>zip_55442</th>\n",
       "      <th>zip_55443</th>\n",
       "      <th>zip_55444</th>\n",
       "      <th>zip_55445</th>\n",
       "      <th>zip_55446</th>\n",
       "      <th>zip_55447</th>\n",
       "      <th>zip_55448</th>\n",
       "      <th>zip_55449</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198000.0</td>\n",
       "      <td>45.237189</td>\n",
       "      <td>-93.409535</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>1996</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>285985.0</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>415000.0</td>\n",
       "      <td>45.278217</td>\n",
       "      <td>-93.407533</td>\n",
       "      <td>3108.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>431995.0</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>329900.0</td>\n",
       "      <td>45.143781</td>\n",
       "      <td>-93.021604</td>\n",
       "      <td>1814.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>318162.0</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>280000.0</td>\n",
       "      <td>45.283700</td>\n",
       "      <td>-93.332023</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>290365.0</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>237000.0</td>\n",
       "      <td>45.105931</td>\n",
       "      <td>-93.261656</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>1959</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>246844.0</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   totPurchaseAmt   latitude  longitude  livingArea  yearBuilt  \\\n",
       "1        198000.0  45.237189 -93.409535      1716.0       1996   \n",
       "3        415000.0  45.278217 -93.407533      3108.0       1985   \n",
       "4        329900.0  45.143781 -93.021604      1814.0       2001   \n",
       "6        280000.0  45.283700 -93.332023      1993.0       1976   \n",
       "7        237000.0  45.105931 -93.261656      2058.0       1959   \n",
       "\n",
       "   averageSchoolRating  zestimate  sentiment  bathrooms_1.0  bathrooms_1.2  \\\n",
       "1             5.333333   285985.0     0.4939              0              0   \n",
       "3             6.333333   431995.0     0.2617              0              0   \n",
       "4             6.500000   318162.0     0.2732              0              0   \n",
       "6             7.333333   290365.0     0.9428              0              0   \n",
       "7             3.666667   246844.0     0.9869              0              0   \n",
       "\n",
       "   ...  zip_55437  zip_55441  zip_55442  zip_55443  zip_55444  zip_55445  \\\n",
       "1  ...          0          0          0          0          0          0   \n",
       "3  ...          0          0          0          0          0          0   \n",
       "4  ...          0          0          0          0          0          0   \n",
       "6  ...          0          0          0          0          0          0   \n",
       "7  ...          0          0          0          0          0          0   \n",
       "\n",
       "   zip_55446  zip_55447  zip_55448  zip_55449  \n",
       "1          0          0          0          0  \n",
       "3          0          0          0          0  \n",
       "4          0          0          0          0  \n",
       "6          0          0          0          0  \n",
       "7          0          0          0          0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(data=df, columns=[\"bathrooms\", \"bedrooms\", \"zip\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"totPurchaseAmt\", \"latitude\", \"longitude\"])\n",
    "y = df[\"totPurchaseAmt\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "X_train_zestimate = X_train[\"zestimate\"]\n",
    "X_train = X_train.drop(columns=[\"zestimate\"])\n",
    "\n",
    "X_test_zestimate = X_test[\"zestimate\"]\n",
    "X_test = X_test.drop(columns=[\"zestimate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Don't cheat - fit only on training data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "n_cols = X_train.shape[1]\n",
    "cnn_model.add(Dense(16, activation='relu', input_shape=(n_cols,)))\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dense(256, activation='relu'))\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dense(16, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='mean_absolute_error', metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 101613.4531 - mae: 101613.4531 - val_loss: 67089.0469 - val_mae: 67089.0469\n",
      "Epoch 2/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 61632.3242 - mae: 61632.3242 - val_loss: 63095.7227 - val_mae: 63095.7227\n",
      "Epoch 3/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 58820.8867 - mae: 58820.8867 - val_loss: 61500.8555 - val_mae: 61500.8555\n",
      "Epoch 4/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 58246.1797 - mae: 58246.1797 - val_loss: 63786.1289 - val_mae: 63786.1289\n",
      "Epoch 5/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 57470.8594 - mae: 57470.8594 - val_loss: 62653.6914 - val_mae: 62653.6914\n",
      "Epoch 6/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56896.6797 - mae: 56896.6797 - val_loss: 61491.9453 - val_mae: 61491.9453\n",
      "Epoch 7/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56599.4922 - mae: 56599.4922 - val_loss: 61033.8750 - val_mae: 61033.8750\n",
      "Epoch 8/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56415.1484 - mae: 56415.1484 - val_loss: 60503.7695 - val_mae: 60503.7695\n",
      "Epoch 9/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56060.4648 - mae: 56060.4648 - val_loss: 60681.9844 - val_mae: 60681.9844\n",
      "Epoch 10/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56526.0742 - mae: 56526.0742 - val_loss: 61132.6914 - val_mae: 61132.6914\n",
      "Epoch 11/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 55861.0977 - mae: 55861.0977 - val_loss: 59756.2852 - val_mae: 59756.2852\n",
      "Epoch 12/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 56091.1914 - mae: 56091.1914 - val_loss: 60993.3047 - val_mae: 60993.3047\n",
      "Epoch 13/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 55862.5234 - mae: 55862.5234 - val_loss: 63865.2461 - val_mae: 63865.2461\n",
      "Epoch 14/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 55674.4336 - mae: 55674.4336 - val_loss: 60605.3477 - val_mae: 60605.3477\n",
      "Epoch 15/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 55372.9062 - mae: 55372.9062 - val_loss: 60158.1445 - val_mae: 60158.1445\n",
      "Epoch 16/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54811.8633 - mae: 54811.8633 - val_loss: 60781.1641 - val_mae: 60781.1641\n",
      "Epoch 17/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54897.2148 - mae: 54897.2148 - val_loss: 62059.8164 - val_mae: 62059.8164\n",
      "Epoch 18/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 55147.5586 - mae: 55147.5586 - val_loss: 65293.5234 - val_mae: 65293.5234\n",
      "Epoch 19/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54834.5742 - mae: 54834.5742 - val_loss: 62986.2148 - val_mae: 62986.2148\n",
      "Epoch 20/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 55322.8164 - mae: 55322.8164 - val_loss: 63520.9219 - val_mae: 63520.9219\n",
      "Epoch 21/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54406.7734 - mae: 54406.7734 - val_loss: 64092.7422 - val_mae: 64092.7422\n",
      "Epoch 22/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54423.8672 - mae: 54423.8672 - val_loss: 60227.5898 - val_mae: 60227.5898\n",
      "Epoch 23/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54321.1250 - mae: 54321.1250 - val_loss: 59915.3633 - val_mae: 59915.3633\n",
      "Epoch 24/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54812.0430 - mae: 54812.0430 - val_loss: 60345.3086 - val_mae: 60345.3086\n",
      "Epoch 25/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53884.6602 - mae: 53884.6602 - val_loss: 64511.4805 - val_mae: 64511.4805\n",
      "Epoch 26/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54122.0078 - mae: 54122.0078 - val_loss: 60114.0273 - val_mae: 60114.0273\n",
      "Epoch 27/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54084.0742 - mae: 54084.0742 - val_loss: 60023.9453 - val_mae: 60023.9453\n",
      "Epoch 28/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53961.6328 - mae: 53961.6328 - val_loss: 61153.1133 - val_mae: 61153.1133\n",
      "Epoch 29/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54004.5508 - mae: 54004.5508 - val_loss: 60571.5703 - val_mae: 60571.5703\n",
      "Epoch 30/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53538.8594 - mae: 53538.8594 - val_loss: 60591.8711 - val_mae: 60591.8711\n",
      "Epoch 31/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53808.2227 - mae: 53808.2227 - val_loss: 60805.6758 - val_mae: 60805.6758\n",
      "Epoch 32/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 54151.0586 - mae: 54151.0586 - val_loss: 60679.3359 - val_mae: 60679.3359\n",
      "Epoch 33/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53213.2539 - mae: 53213.2539 - val_loss: 60795.1836 - val_mae: 60795.1836\n",
      "Epoch 34/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53376.5430 - mae: 53376.5430 - val_loss: 60110.4609 - val_mae: 60110.4609\n",
      "Epoch 35/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53725.7812 - mae: 53725.7812 - val_loss: 60626.6445 - val_mae: 60626.6445\n",
      "Epoch 36/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53394.3672 - mae: 53394.3672 - val_loss: 61574.1992 - val_mae: 61574.1992\n",
      "Epoch 37/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53333.1953 - mae: 53333.1953 - val_loss: 62005.5352 - val_mae: 62005.5352\n",
      "Epoch 38/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53231.2930 - mae: 53231.2930 - val_loss: 63619.0430 - val_mae: 63619.0430\n",
      "Epoch 39/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53155.8008 - mae: 53155.8008 - val_loss: 64433.4844 - val_mae: 64433.4844\n",
      "Epoch 40/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53428.1641 - mae: 53428.1641 - val_loss: 61173.2617 - val_mae: 61173.2617\n",
      "Epoch 41/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53183.8906 - mae: 53183.8906 - val_loss: 60493.8750 - val_mae: 60493.8750\n",
      "Epoch 42/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52987.2383 - mae: 52987.2383 - val_loss: 61623.7812 - val_mae: 61623.7812\n",
      "Epoch 43/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 53212.4258 - mae: 53212.4258 - val_loss: 62174.2656 - val_mae: 62174.2656\n",
      "Epoch 44/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52944.5547 - mae: 52944.5547 - val_loss: 62036.6133 - val_mae: 62036.6133\n",
      "Epoch 45/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52802.4023 - mae: 52802.4023 - val_loss: 60390.3281 - val_mae: 60390.3281\n",
      "Epoch 46/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52540.9688 - mae: 52540.9688 - val_loss: 61006.7344 - val_mae: 61006.7344\n",
      "Epoch 47/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52740.1484 - mae: 52740.1484 - val_loss: 60214.6875 - val_mae: 60214.6875\n",
      "Epoch 48/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52791.2383 - mae: 52791.2383 - val_loss: 60752.8008 - val_mae: 60752.8008\n",
      "Epoch 49/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52688.6211 - mae: 52688.6211 - val_loss: 60677.1602 - val_mae: 60677.1602\n",
      "Epoch 50/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52489.6875 - mae: 52489.6875 - val_loss: 61694.8555 - val_mae: 61694.8555\n",
      "Epoch 51/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52406.7773 - mae: 52406.7773 - val_loss: 60503.3672 - val_mae: 60503.3672\n",
      "Epoch 52/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52267.4258 - mae: 52267.4258 - val_loss: 63777.8711 - val_mae: 63777.8711\n",
      "Epoch 53/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52261.4922 - mae: 52261.4922 - val_loss: 60320.5078 - val_mae: 60320.5078\n",
      "Epoch 54/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51927.7148 - mae: 51927.7148 - val_loss: 62426.8047 - val_mae: 62426.8047\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/528 [==============================] - 3s 6ms/step - loss: 52144.0820 - mae: 52144.0820 - val_loss: 61351.8867 - val_mae: 61351.8867\n",
      "Epoch 56/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52231.5664 - mae: 52231.5664 - val_loss: 62280.5625 - val_mae: 62280.5625\n",
      "Epoch 57/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52241.4805 - mae: 52241.4805 - val_loss: 62753.4258 - val_mae: 62753.4258\n",
      "Epoch 58/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 51866.5742 - mae: 51866.5742 - val_loss: 60533.4688 - val_mae: 60533.4688\n",
      "Epoch 59/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 51845.4727 - mae: 51845.4727 - val_loss: 63091.2227 - val_mae: 63091.2227\n",
      "Epoch 60/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51855.9141 - mae: 51855.9141 - val_loss: 60880.5156 - val_mae: 60880.5156\n",
      "Epoch 61/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51815.2461 - mae: 51815.2461 - val_loss: 61570.9414 - val_mae: 61570.9414\n",
      "Epoch 62/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 52142.1172 - mae: 52142.1172 - val_loss: 61463.9570 - val_mae: 61463.9570\n",
      "Epoch 63/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51446.5703 - mae: 51446.5703 - val_loss: 61037.1445 - val_mae: 61037.1445\n",
      "Epoch 64/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51628.3359 - mae: 51628.3359 - val_loss: 60386.4062 - val_mae: 60386.4062\n",
      "Epoch 65/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51593.7031 - mae: 51593.7031 - val_loss: 63410.4062 - val_mae: 63410.4062\n",
      "Epoch 66/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51567.9141 - mae: 51567.9141 - val_loss: 61803.5703 - val_mae: 61803.5703\n",
      "Epoch 67/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51735.4766 - mae: 51735.4766 - val_loss: 61287.0781 - val_mae: 61287.0781\n",
      "Epoch 68/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51770.9336 - mae: 51770.9336 - val_loss: 62029.0898 - val_mae: 62029.0898\n",
      "Epoch 69/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 51324.5586 - mae: 51324.5586 - val_loss: 60835.1797 - val_mae: 60835.1797\n",
      "Epoch 70/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51146.9805 - mae: 51146.9805 - val_loss: 63770.4727 - val_mae: 63770.4727\n",
      "Epoch 71/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 51265.7031 - mae: 51265.7031 - val_loss: 63615.1641 - val_mae: 63615.1641\n",
      "Epoch 72/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50919.5469 - mae: 50919.5469 - val_loss: 61305.5039 - val_mae: 61305.5039\n",
      "Epoch 73/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51198.6328 - mae: 51198.6328 - val_loss: 61993.4766 - val_mae: 61993.4766\n",
      "Epoch 74/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50875.1602 - mae: 50875.1602 - val_loss: 62505.9375 - val_mae: 62505.9375\n",
      "Epoch 75/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50912.4844 - mae: 50912.4844 - val_loss: 62361.3047 - val_mae: 62361.3047\n",
      "Epoch 76/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 51140.4375 - mae: 51140.4375 - val_loss: 61552.2031 - val_mae: 61552.2031\n",
      "Epoch 77/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50859.4688 - mae: 50859.4688 - val_loss: 61895.7695 - val_mae: 61895.7695\n",
      "Epoch 78/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50785.3320 - mae: 50785.3320 - val_loss: 63051.6836 - val_mae: 63051.6836\n",
      "Epoch 79/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50923.7812 - mae: 50923.7812 - val_loss: 64185.8594 - val_mae: 64185.8594\n",
      "Epoch 80/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50686.9297 - mae: 50686.9297 - val_loss: 62520.2344 - val_mae: 62520.2344\n",
      "Epoch 81/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50567.5430 - mae: 50567.5430 - val_loss: 63302.3047 - val_mae: 63302.3047\n",
      "Epoch 82/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50734.0859 - mae: 50734.0859 - val_loss: 62380.4961 - val_mae: 62380.4961\n",
      "Epoch 83/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50780.2656 - mae: 50780.2656 - val_loss: 62274.7266 - val_mae: 62274.7266\n",
      "Epoch 84/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50351.0273 - mae: 50351.0273 - val_loss: 63025.5234 - val_mae: 63025.5234\n",
      "Epoch 85/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50311.6289 - mae: 50311.6289 - val_loss: 62806.4102 - val_mae: 62806.4102\n",
      "Epoch 86/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50315.6758 - mae: 50315.6758 - val_loss: 63073.8594 - val_mae: 63073.8594\n",
      "Epoch 87/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50088.9219 - mae: 50088.9219 - val_loss: 63816.0898 - val_mae: 63816.0898\n",
      "Epoch 88/100\n",
      "528/528 [==============================] - 3s 5ms/step - loss: 50194.4961 - mae: 50194.4961 - val_loss: 64288.8984 - val_mae: 64288.8984\n",
      "Epoch 89/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49969.4648 - mae: 49969.4648 - val_loss: 64240.3555 - val_mae: 64240.3555\n",
      "Epoch 90/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50512.5938 - mae: 50512.5938 - val_loss: 63441.2617 - val_mae: 63441.2617\n",
      "Epoch 91/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50054.4375 - mae: 50054.4375 - val_loss: 64152.3398 - val_mae: 64152.3398\n",
      "Epoch 92/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50164.9531 - mae: 50164.9531 - val_loss: 62920.1992 - val_mae: 62920.1992\n",
      "Epoch 93/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49783.6445 - mae: 49783.6445 - val_loss: 65286.6953 - val_mae: 65286.6953\n",
      "Epoch 94/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49832.6797 - mae: 49832.6797 - val_loss: 63589.3125 - val_mae: 63589.3125\n",
      "Epoch 95/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 50376.8281 - mae: 50376.8281 - val_loss: 63948.3828 - val_mae: 63948.3828\n",
      "Epoch 96/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49592.6797 - mae: 49592.6797 - val_loss: 63788.0781 - val_mae: 63788.0781\n",
      "Epoch 97/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49615.5000 - mae: 49615.5000 - val_loss: 64540.4844 - val_mae: 64540.4844\n",
      "Epoch 98/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49744.7617 - mae: 49744.7617 - val_loss: 63839.0508 - val_mae: 63839.0508\n",
      "Epoch 99/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49668.0312 - mae: 49668.0312 - val_loss: 65861.1172 - val_mae: 65861.1172\n",
      "Epoch 100/100\n",
      "528/528 [==============================] - 3s 6ms/step - loss: 49619.0859 - mae: 49619.0859 - val_loss: 63905.0391 - val_mae: 63905.0391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a6229d4b38>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Linear Regression ===\n",
      "Mean Absolute Error: 309403437005579.5\n",
      "Mean Squared Error: 3.846929611762503e+32\n",
      "Root Mean Squared Error: 1.961359123608551e+16\n",
      "\n",
      "\n",
      "=== Decision Tree ===\n",
      "Mean Absolute Error: 78685.99993239601\n",
      "Mean Squared Error: 22522082270.635963\n",
      "Root Mean Squared Error: 150073.58951739632\n",
      "\n",
      "\n",
      "=== Ridge Regression ===\n",
      "Mean Absolute Error: 61904.44350288182\n",
      "Mean Squared Error: 13392450661.323738\n",
      "Root Mean Squared Error: 115725.75625729882\n",
      "\n",
      "\n",
      "=== Least Angle Regression ===\n",
      "Mean Absolute Error: 61892.11067172486\n",
      "Mean Squared Error: 13392633901.665377\n",
      "Root Mean Squared Error: 115726.54795536492\n",
      "\n",
      "\n",
      "=== Bayesian Ridge Regression ===\n",
      "Mean Absolute Error: 61813.5531835889\n",
      "Mean Squared Error: 13400914624.470406\n",
      "Root Mean Squared Error: 115762.3195364986\n",
      "\n",
      "\n",
      "=== SGD Regressor ===\n",
      "Mean Absolute Error: 3396843622.0418334\n",
      "Mean Squared Error: 9.427794303313826e+21\n",
      "Root Mean Squared Error: 97096829522.46086\n",
      "\n",
      "\n",
      "=== Nearest Neighbors Regression ===\n",
      "Mean Absolute Error: 67588.08312181162\n",
      "Mean Squared Error: 16742740623.026981\n",
      "Root Mean Squared Error: 129393.74259610462\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "Mean Absolute Error: 58011.627401460806\n",
      "Mean Squared Error: 12808844889.633244\n",
      "Root Mean Squared Error: 113176.16749843248\n",
      "\n",
      "\n",
      "=== Gradient Boosting Regressor ===\n",
      "Mean Absolute Error: 60051.97994253719\n",
      "Mean Squared Error: 12762800297.239418\n",
      "Root Mean Squared Error: 112972.56435630475\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    #\"Neural Network\" : cnn_model,\n",
    "    \"Linear Regression\" : linear_model.LinearRegression(), \n",
    "    #\"Support Vector Machine\" : svm.SVR(),\n",
    "    \"Decision Tree\" : DecisionTreeRegressor(),\n",
    "    \"Ridge Regression\" : linear_model.Ridge(alpha=.5),\n",
    "    \"Least Angle Regression\" : linear_model.LassoLars(alpha=.1),\n",
    "    \"Bayesian Ridge Regression\" : linear_model.BayesianRidge(),\n",
    "    \"SGD Regressor\" : linear_model.SGDRegressor(),\n",
    "    \"Nearest Neighbors Regression\" : neighbors.KNeighborsRegressor(),\n",
    "    #\"Gaussian Process\" : gaussian_process.GaussianProcessRegressor(),\n",
    "    \"Random Forest\" : ensemble.RandomForestRegressor(),\n",
    "    'Gradient Boosting Regressor' : ensemble.GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "\n",
    "    if model_name == \"Neural Network\":\n",
    "        model.fit(X_train, y_train, validation_split=0.1, epochs=100, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print (\"=== \" + model_name + \" ===\")\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-63a2c52d74c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1529\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prate\\anaconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 20)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = ensemble.RandomForestRegressor()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
